<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <meta name="description" content="Practical Machine Learning Course Project : ">

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Practical Machine Learning Course Project</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/BenPiggot/PracticalMachineLearning_CourseProject">View on GitHub</a>

          <h1 id="project_title">Practical Machine Learning Course Project</h1>
          <h2 id="project_tagline"></h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/BenPiggot/PracticalMachineLearning_CourseProject/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/BenPiggot/PracticalMachineLearning_CourseProject/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <p><strong><em>Ben Piggot</em></strong></p>

<p><strong><em>September 17, 2014</em></strong></p>

<h3>
<a name="synopsis" class="anchor" href="#synopsis"><span class="octicon octicon-link"></span></a>Synopsis</h3>

<p>This brief analysis makes use of data used by Velloso et al. in their 2013 study, "Qualitative Activity Recognition of Weight Lifting Exercises." (See: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a> for more information). Using this data, it creates a model designed to predict the manner in which individuals perform weightlifting exercises.</p>

<h3>
<a name="data-processing" class="anchor" href="#data-processing"><span class="octicon octicon-link"></span></a>Data Processing</h3>

<p>My first step is to load in the training set data I use to build my model from the url below. Additionally, I load the plyr, caret, and randomForest packages.</p>

<pre lang="r,"><code>myurl &lt;- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
download.file(url=myurl, destfile="pml-training.csv", method="curl")
TrainingSet &lt;- read.csv("pml-training.csv")
library(plyr)
library(caret)
library(randomForest)
</code></pre>

<p>Once the data is loaded into my working directory, I clean the original training set. I remove variables that largely consist of missing data and variables that do not measure physical activity. I also eliminate variables that R falsely recognizes to be factor variables, but which in fact mostly contain missing or garbled information in the original .csv file. I make sure to remove and then re-attach the "classe" variability to my training set before eliminating the rest of the factors in the Training Set. The "classe" variable measures the outcome of interest in my analysis. As a result of my cleaning, the number of variables I will use in my model is reduced from 161 to 53.</p>

<pre lang="r,"><code>CleanedTrainingSet &lt;- TrainingSet[ , colSums(is.na(TrainingSet)) &lt; 15000] 
CleanedTrainingSet &lt;- CleanedTrainingSet[,-c(1:7)]
CleanedTrainingSet1 &lt;- CleanedTrainingSet[,-86]
CleanedTrainingSet1 &lt;- CleanedTrainingSet1[, !sapply(CleanedTrainingSet1, is.factor)]
CleanedTrainingSet1 &lt;- cbind(CleanedTrainingSet1, CleanedTrainingSet$classe)
CleanedTrainingSet1 &lt;- rename(CleanedTrainingSet1, c("CleanedTrainingSet$classe"="classe"))
</code></pre>

<p>Next, I subset the cleaned training set into two halves. The first half will be used to construct my model; the second half will be used to cross-validate the model I build.</p>

<pre lang="r,"><code>set.seed(21)
Sample1&lt;- sample(1:dim(CleanedTrainingSet1)[1],size=dim(CleanedTrainingSet1)[1]/2,replace=F)
SampleTrain &lt;- CleanedTrainingSet1[Sample1,]
CVTrain &lt;- CleanedTrainingSet1[-Sample1,]
</code></pre>

<h3>
<a name="building-a-model" class="anchor" href="#building-a-model"><span class="octicon octicon-link"></span></a>Building a Model</h3>

<p>I then build my model, predicting the classe variable utilizing a Random Forest algorithm as called inside the train() function. I then use this model to predict the values of the sample from which I constructed my model (SampleTrain). The results are then stored and presented in a confusion matrix.</p>

<pre lang="r,"><code>RFTrain &lt;- train(classe ~., method="rf", data=SampleTrain)
Prediction1 &lt;- predict(RFTrain$finalModel, SampleTrain)
Prediction1.Summary &lt;- confusionMatrix(SampleTrain$classe, Prediction1)
Prediction1.Summary
</code></pre>

<h3>
<a name="cross-validating-the-model" class="anchor" href="#cross-validating-the-model"><span class="octicon octicon-link"></span></a>Cross-Validating the Model</h3>

<p>As the results above suggest, the model I have built predicts the classe outcome with perfect accuracy. However, this level of accuracy could be misleading as it might be the result of overfitting. Therefore, I cross-validate my model on two samples drawn at random from the half of the training set I did not use to construct my model (CVTrain).</p>

<pre lang="r,"><code>set.seed(51)
Sample2 &lt;- sample(1:dim(CVTrain)[1],size=dim(CVTrain)[1]/20,replace=F)
CVSample1 &lt;- CVTrain[Sample2,]
Prediction2 &lt;- predict(RFTrain$finalModel, CVSample1)
Prediction2.Summary &lt;- confusionMatrix(CVSample1$classe, Prediction2)
Prediction2.Summary
</code></pre>

<p>As the numbers above indicate, the model proves highly accurate in its first out-of-sample test: it correctly predicts 99.2% of the actual values. Below, the second out-of-sample prediction shows similar levels of accuracy: it correctly predicts 98.8% of the actual values. Accordingly, I expect the out-of-sample error for my model to be approximately 1%.</p>

<pre lang="r,"><code>set.seed(81)
Sample3 &lt;- sample(1:dim(CVTrain)[1],size=dim(CVTrain)[1]/20,replace=F)
CVSample2 &lt;- CVTrain[Sample3,]
Prediction3 &lt;- predict(RFTrain$finalModel, CVSample2)
Prediction3.Summary &lt;- confusionMatrix(CVSample2$classe, Prediction3)
Prediction3.Summary
</code></pre>

<h3>
<a name="testing-the-model" class="anchor" href="#testing-the-model"><span class="octicon octicon-link"></span></a>Testing the Model</h3>

<p>Now that I am now quite confident my model accurately predicts exercise style as measured by the "classe" variable, I load in the testing set data. I then clean the testing set using the same procedures I used to clean the training set. </p>

<pre lang="r,"><code>myurl &lt;- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
download.file(url=myurl, destfile="pml-testing.csv", method="curl")
TestingSet &lt;- read.csv("pml-testing.csv")
CleanedTestingSet &lt;- TestingSet[ , colSums(is.na(TestingSet)) &lt; 10] 
CleanedTestingSet &lt;- CleanedTestingSet[,-c(1:7)]
CleanedTestingSet &lt;- CleanedTestingSet[, !sapply(CleanedTestingSet, is.factor)]
</code></pre>

<p>Once the testing set has been properly prepared, I predict its "classe" values using my model. The 20 predicted outcomes can be seen below. All 20 predictions are correct: the model has performed very well on the testing set.</p>

<pre lang="r,"><code>PredictionFinal &lt;- predict(RFTrain$finalModel, CleanedTestingSet)
PredictionFinal
</code></pre>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Practical Machine Learning Course Project maintained by <a href="https://github.com/BenPiggot">BenPiggot</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
